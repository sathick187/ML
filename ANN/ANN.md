ğŸ“Š Customer Churn Prediction using ANN (TensorFlow & Keras)

This project builds an Artificial Neural Network (ANN) to predict customer churn (whether a customer will leave the bank or not) using TensorFlow/Keras.
It covers data preprocessing, feature engineering, model training, evaluation, and TensorBoard visualization.

ğŸ“ Project Overview

Customer churn prediction is a binary classification problem where:

1 â†’ Customer exited

0 â†’ Customer stayed

The model learns patterns from customer data such as age, balance, geography, gender, and credit score.

ğŸ› ï¸ Technologies Used

Python 3.x

Pandas

NumPy

Scikit-learn

TensorFlow / Keras

TensorBoard

VS Code

ğŸ“‚ Dataset

File: Churn_Modelling.csv

Columns used:

CreditScore

Geography

Gender

Age

Tenure

Balance

NumOfProducts

HasCrCard

IsActiveMember

EstimatedSalary

Exited (Target)

Dropped Columns:

RowNumber

CustomerId

Surname

These columns do not contribute to prediction.

ğŸ”„ Data Preprocessing Steps
1ï¸âƒ£ Drop Unnecessary Columns
data.drop(["RowNumber","CustomerId","Surname"], axis=1)

2ï¸âƒ£ Label Encoding (Gender)

Female â†’ 0

Male â†’ 1

Used because gender has only two categories.

3ï¸âƒ£ One-Hot Encoding (Geography)

Converts categorical geography values into binary columns to avoid ordinal bias.

Example:

France â†’ Geography_France = 1
Spain  â†’ Geography_Spain = 1
Germany â†’ Geography_Germany = 1

4ï¸âƒ£ Feature Scaling
StandardScaler()


Scaling is mandatory for neural networks to ensure stable and fast learning.

5ï¸âƒ£ Train-Test Split

80% Training

20% Testing

train_test_split(test_size=0.2, random_state=42)

ğŸ§  ANN Model Architecture
Input Layer  â†’ 64 neurons (ReLU)
Hidden Layer â†’ 32 neurons (ReLU)
Output Layer â†’ 1 neuron (Sigmoid)

Why this architecture?

ReLU avoids vanishing gradient

Sigmoid outputs probability (0â€“1)

Binary Crossentropy suits binary classification

âš™ï¸ Model Compilation

Optimizer: Adam

Learning Rate: 0.01

Loss: Binary Crossentropy

Metric: Accuracy

â¹ï¸ Early Stopping

Stops training when validation loss does not improve for 10 epochs.

Benefits:

Prevents overfitting

Saves best weights automatically

ğŸ“Š TensorBoard Visualization (VS Code)
âŒ Not Supported in .py files

Jupyter magic commands like:

%load_ext tensorboard
%tensorboard


âŒ Do NOT work in VS Code .py files

âœ… Correct Way (VS Code Terminal)
Step 1: Open Terminal
Ctrl + `

Step 2: Run TensorBoard
tensorboard --logdir logs/fit

Step 3: Open Browser
http://localhost:6006


You can now view:

Training vs Validation Loss

Training vs Validation Accuracy

Weight histograms

ğŸ’¾ Model Saving
model.save("model.h5")


Saved for:

Reuse

Deployment

API integration

ğŸ’¾ Scaler Saving
pickle.dump(scaler, open("scaler.pkl", "wb"))


Ensures same scaling during prediction.

ğŸ“¦ Installation (pip)

Run the following commands:

pip install pandas
pip install numpy
pip install scikit-learn
pip install tensorflow
pip install tensorboard

ğŸš€ How to Run the Project

Clone / Download the project

Place Churn_Modelling.csv correctly

Run the training script:

python churn_ann.py


Launch TensorBoard:

tensorboard --logdir logs/fit

ğŸ¯ Output

Trained ANN model (model.h5)

Scaler file (scaler.pkl)

TensorBoard logs (logs/fit/)

Accuracy & loss visualization

ğŸ§ª Future Improvements

Hyperparameter tuning

Dropout layers

Class imbalance handling

Flask / Streamlit deployment

Real-time prediction API

ğŸ§  Interview Explanation (One Line)

This project predicts customer churn using an Artificial Neural Network with proper preprocessing, feature scaling, early stopping, and TensorBoard visualization to ensure optimal and stable model performance.

If you want, next I can:

âœ… Add prediction script

âœ… Add Streamlit UI

âœ… Convert this into GitHub-ready structure

âœ… Add diagrams for ANN

Just tell me ğŸ‘ğŸ”¥